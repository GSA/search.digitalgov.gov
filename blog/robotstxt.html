<!DOCTYPE html>
<html lang="en">
<head>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta charset="utf-8">
  
  <title>Robots.txt Files</title>
  <meta name="description" content="">
  <meta name="author" content="">
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,700" media="screen" rel="stylesheet" type="text/css" />
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" media="screen" rel="stylesheet" type="text/css" />
  <link href="https://fonts.googleapis.com/css?family=Merriweather:400,700" media="screen" rel="stylesheet" type="text/css" />
  <link href="/bootstrap/css/bootstrap.css" rel="stylesheet">
  <link rel="stylesheet" href="/stylesheets/font-awesome.min.css">
  <!--[if IE 7]>
  <link rel="stylesheet" href="/stylesheets/font-awesome-ie7.min.css">
  <![endif]-->

  <!--<link href="../assets/css/bootstrap-responsive.css" rel="stylesheet">-->
  <link href="/stylesheets/custom.css" rel="stylesheet">

  <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
  <script src="/javascripts/html5shiv.js"></script>
  <![endif]-->

  <!-- Fav and touch icons -->
  <!--  <link rel="apple-touch-icon-precomposed" sizes="144x144"
          href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114"
          href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72"
          href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
  <link rel="shortcut icon" href="https://d3qcdigd1fhos0.cloudfront.net/blog/img/favicon.ico">
  <link rel='alternate' type='application/atom+xml' title='search.gov Atom feed' href='/all.atom' />
  <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
  <script src="/javascripts/bootstrap3-typeahead.js"></script>
 </head>

<body>
<nav class="navbar navbar-inverse navbar-fixed-top">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <a class="navbar-brand" href="/">
        <span class="search">Search.gov</span>
      </a>
    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">

      <form class="navbar-form navbar-left form-search" accept-charset="UTF-8" action="https://find.search.gov/search/" id="search-form" method="get">
        <div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /></div>
        <input name="affiliate" id="affiliate" type="hidden" value="usasearch">
        <div class="input-group input-append">
          <label for="search-query" class="hide">Query</label>

          <input name="query" autocomplete="off"  type="text" class="typeahead form-control search-query" id="search-query" data-provide="typeahead" >
          <span class="input-group-btn">
            <button type="submit" class="btn btn-nav" aria-label="Left Align" id="search-button">
              <span class="glyphicon glyphicon-search" aria-hidden="true"></span>
            </button>
          </span>
        </div>
      </form>
      <div class="nav navbar-right">
          <a href="https://search.usa.gov/sites" class="navbar-brand"><i
              class="icon-user icon-white"></i>&nbsp;Login</a>
      </div>&nbsp;&nbsp;&nbsp;<div class="nav navbar-right">
          <a href="http://search.usa.gov/signup" class="navbar-brand">Sign up</a>
      </div>&nbsp;&nbsp;&nbsp;<div class="nav navbar-right">
          <a href="https://search.gov/status.html" class="navbar-brand">System Status</a>
      </div>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>


<div class="col-md-offset-2 col-md-8  hidden-sm hidden-md hidden-lg">

  <form class="form-search" accept-charset="UTF-8" action="https://find.search.gov/search/" id="search-form" method="get">
    <input name="affiliate" id="affiliate" type="hidden" value="usasearch">
    <div class="input-group input-append">
      <label for="search-query" class="hide">Query</label>

      <input name="query" autocomplete="off"  type="text" class=" form-control search-query" id="search-query"  >
      <span class="input-group-btn">
        <button type="submit" class="btn btn-primary" aria-label="Left Align" id="search-button">
          <span class="glyphicon glyphicon-search" aria-hidden="true"></span>
        </button>
      </span>
    </div>
  </form>
</div>


<div class="container-fluid">
  <div class="col-md-8 col-md-offset-2">
    <!-- do not remove as used to parse in usasearch -->
    <main id="main-container">
      <article class="article feature" style="padding:0 30px; margin-top: 10px;">
  
  <h1>
    <a href="/blog/robotstxt.html">Robots.txt Files</a>
  </h1>
  

  <div class='post-content'>
    <p>A <code>/robots.txt</code> file is a text file that instructs automated web bots on how to crawl and/or index a website. Web teams use them to provide information about what site directories should or should not be crawled, how quickly content should be accessed, and which bots are welcome on the site.</p>

<h2 id="what-should-my-robotstxt-file-look-like">What should my robots.txt file look like?</h2>
<p>Please refer to the <a href="http://www.robotstxt.org/robotstxt.html">robots.txt protocol</a>  <i class="icon-external-link"><span>(External link)</span></i> for detailed information on how and where to create your robots.txt. Key points to keep in mind:</p>

<ul>
  <li>The file must be located at the root of the domain, and each subdomain needs its own file.</li>
  <li>The robots.txt protocol is case sensitive.</li>
  <li>It’s easy to accidentally block crawling of everything
    <ul>
      <li><code>Disallow: /</code> means disallow everything</li>
      <li><code>Disallow:  </code> means disallow nothing, thus allowing everything</li>
      <li><code>Allow: /</code> means allow everything</li>
      <li><code>Allow:  </code> means allow nothing, thus disallowing everything</li>
    </ul>
  </li>
  <li>The instructions in robots.txt are guidance for bots, not binding requirements.</li>
</ul>

<h2 id="how-can-i-optimize-my-robotstxt-for-searchgov">How can I optimize my robots.txt for Search.gov?</h2>

<h3 id="crawl-delay">Crawl delay</h3>
<p>A robots.txt file may specify a “crawl delay” directive for one or more user agents, which tells a bot how quickly it can request pages from a website. For example, a crawl delay of 10 specifies that a crawler should not request a new page more than every 10 seconds.  We recommend a crawl-delay of 2 seconds for our <code>usasearch</code> user agent, and setting a higher crawl delay for all other bots. The lower the crawl delay, the faster Search.gov will be able to index your site. In the robots.txt file, it would look like this:</p>

<pre><code>User-agent: usasearch  
Crawl-delay: 2

User-agent: *
Crawl-delay: 10
</code></pre>

<h3 id="xml-sitemaps">XML Sitemaps</h3>
<p>Your robots.txt file should also list one or more of your <a href="https://search.gov/blog/sitemaps.html">XML sitemaps</a>. For example:</p>

<pre><code>Sitemap: https://www.exampleagency.gov/sitemap.xml
Sitemap: https://www.exampleagency.gov/independent-subsection-sitemap.xml
</code></pre>
<ul>
  <li>Only list sitemaps for the domain matching where the robots.txt file is. A different subdomain’s sitemap should be listed on that subdomain’s robots.txt.</li>
</ul>

<h3 id="allow-only-the-content-that-you-want-searchable">Allow only the content that you want searchable</h3>
<p>We recommend disallowing any directories or files that should not be searchable. For example:</p>

<pre><code>Disallow: /archive/
Disallow: /news-1997/
Disallow: /reports/duplicative-page.html
</code></pre>

<ul>
  <li>Note that if you disallow a directory after it’s been indexed by a search engine, this may not trigger a removal of that content from the index. You’ll need to go into the search engine’s webmaster tools to request removal.</li>
  <li>Also note that search engines may index individual pages within a disallowed folder if the search engine learns about the URL from a non-crawl method, like a link from another site or your sitemap. To ensure a given page is not searchable, set a <a href="/blog/how-search-engines-index-content-better-discoverability.html#robots">robots meta tag</a> on that page.</li>
</ul>

<h3 id="customize-settings-for-different-bots">Customize settings for different bots</h3>
<p>You can set different permissions for different bots. For example, if you want us to index your archived content but don’t want Google or Bing to index it, you can specify that:</p>

<pre><code>User-agent: usasearch  
Crawl-delay: 2
Allow: /archive/

User-agent: *
Crawl-delay: 10
Disallow: /archive/
</code></pre>

<h2 id="robotstxt-checklist">Robots.txt checklist</h2>
<p><i class="icon-check"></i> 1. A robots.txt file has been created in the site’s root directory (<code>https://exampleagency.gov/robots.txt</code>)</p>

<p><i class="icon-check"></i> 2. The robots.txt file disallows any directories and files that automated bots should not crawl</p>

<p><i class="icon-check"></i> 3. The robots.txt file lists one or more <a href="https://search.gov/blog/sitemaps.html">XML sitemaps</a></p>

<p><i class="icon-check"></i> 4. The robots.txt file format has been <a href="http://tools.seochat.com/tools/robots-txt-validator/">validated</a>  <i class="icon-external-link"><span>(External link)</span></i></p>

<h2 id="additional-resources">Additional Resources</h2>
<p><a href="https://yoast.com/ultimate-guide-robots-txt/">Yoast SEO’s Ultimate Guide to Robots.txt</a>  <i class="icon-external-link"><span>(External link)</span></i></p>

<p><a href="https://support.google.com/webmasters/answer/6062608?hl=en&amp;ref_topic=6061961">Google’s “Learn about robots.txt files”</a>  <i class="icon-external-link"><span>(External link)</span></i></p>


  </div>

  <div class='tags'>
    
    <a href="/tagged/how-to"><span class="label label-info">how-to</span></a>
    
    <a href="/tagged/manage-content"><span class="label label-info">manage-content</span></a>
    
    <a href="/tagged/indexing"><span class="label label-info">indexing</span></a>
    
  </div>

  <div class='time'>
    
    </br><span>Page last reviewed or updated:</span>
    
    
    
    
    <a href="/blog/robotstxt.html">
      <time>October 11, 2018</time>
    </a>
  </div>

</article>

    </main>
  </div>
</div>

<footer class="footer">
  <div class="container">
    <p><a href="mailto:search@support.digitalgov.gov">Email us</a> or call us at 202-969-7426</p>
    <p> An Official Website of the U.S. Government <br />
      <a href="https://www.gsa.gov/portal/category/25729">Technology Transformation Service</a>, <a href="https://www.gsa.gov/portal/category/100000">U.S. General Services Administration</a>
    </p>
    <ul class="footer-links list-unstyled list-inline">
      <li><a href="https://www.usa.gov">USA.gov</a></li>
      <li class="muted">&bull;</li>
      <li><a href="/tos.html">Terms of Service</a></li>
      <li class="muted">&bull;</li>
      <li><a href="https://www.digitalgov.gov/about/policies/">Site Policies</a></li>
      <li class="muted">&bull;</li>
      <li><a href="/developer/">Developers</a></li>
    </ul>
  </div>
</footer>

<script type="text/javascript">
  //<![CDATA[
  var usasearch_config = { siteHandle:"usasearch" };

jQuery(document).ready(function() {
  $('.typeahead').typeahead({
      source: function (query, process) {
          return $.get('https://search.usa.gov/sayt?name=usasearch&q=' + query, function (data) {
              return process(data);
          });
      }, minLength: 2
  });
})


  // var script = document.createElement("script");
  // script.type = "text/javascript";
  // script.src = "https://search.usa.gov/javascripts/remote.loader.js";
  // document.getElementsByTagName("head")[0].appendChild(script);

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-31302465-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

  //]]>
</script>

<script async type="text/javascript" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=GSA" id="_fed_an_ua_tag"></script>


</body>
</html>
